# 监控与日志

<cite>
**本文档中引用的文件**  
- [otel_config.py](file://api/configs/observability/otel/otel_config.py)
- [ext_otel.py](file://api/extensions/ext_otel.py)
- [ext_sentry.py](file://api/extensions/ext_sentry.py)
- [sentry_config.py](file://api/configs/extra/sentry_config.py)
- [TraceAppConfig](file://api/models/model.py#L1859-L1889)
- [workflow_app_logs](file://api/models/workflow.py#L816-L849)
- [ops_trace_manager.py](file://api/core/ops/ops_trace_manager.py#L267-L297)
</cite>

## 目录
1. [引言](#引言)
2. [OpenTelemetry 集成配置](#opentelemetry-集成配置)
3. [Sentry 错误监控系统设置](#sentry-错误监控系统设置)
4. [Prometheus 与 Grafana 集成](#prometheus-与-grafana-集成)
5. [日志收集与分析最佳实践](#日志收集与分析最佳实践)
6. [关键监控指标](#关键监控指标)
7. [告警规则配置](#告警规则配置)
8. [故障排查流程](#故障排查流程)

## 引言
本文档详细描述了 Dify 平台的全面监控与日志管理方案。涵盖了 OpenTelemetry 的 trace、metrics 和 logs 采集与导出配置，Sentry 错误监控系统的前后端集成方法，Prometheus 指标监控与 Grafana 仪表板使用，以及基于 ELK/EFK 栈的日志收集、存储和分析最佳实践。同时列出了关键监控指标、告警规则和故障排查流程，确保系统的可观测性和稳定性。

## OpenTelemetry 集成配置

### OpenTelemetry 配置参数
OpenTelemetry 的配置通过 `OTelConfig` 类进行管理，支持 trace、metrics 和 logs 的全面采集与导出。

```mermaid
classDiagram
class OTelConfig {
+bool ENABLE_OTEL
+str OTLP_TRACE_ENDPOINT
+str OTLP_METRIC_ENDPOINT
+str OTLP_BASE_ENDPOINT
+str OTLP_API_KEY
+str OTEL_EXPORTER_TYPE
+str OTEL_EXPORTER_OTLP_PROTOCOL
+float OTEL_SAMPLING_RATE
+int OTEL_BATCH_EXPORT_SCHEDULE_DELAY
+int OTEL_MAX_QUEUE_SIZE
+int OTEL_MAX_EXPORT_BATCH_SIZE
+int OTEL_METRIC_EXPORT_INTERVAL
+int OTEL_BATCH_EXPORT_TIMEOUT
+int OTEL_METRIC_EXPORT_TIMEOUT
}
OTelConfig --> ObservabilityConfig : "继承"
```

**Diagram sources**
- [otel_config.py](file://api/configs/observability/otel/otel_config.py#L1-L59)

**Section sources**
- [otel_config.py](file://api/configs/observability/otel/otel_config.py#L1-L59)

### OpenTelemetry 初始化流程
OpenTelemetry 在应用启动时通过 `ext_otel.py` 进行初始化，自动集成 Flask、Celery、SQLAlchemy、Redis 和 Requests 等组件的监控。

```mermaid
sequenceDiagram
participant App as DifyApp
participant OTel as OpenTelemetry
participant Flask as FlaskInstrumentor
participant Celery as CeleryInstrumentor
participant DB as SQLAlchemyInstrumentor
participant Cache as RedisInstrumentor
participant HTTP as RequestsInstrumentor
App->>OTel : init_app()
OTel->>OTel : setup_context_propagation()
OTel->>OTel : create TracerProvider
OTel->>OTel : create MeterProvider
OTel->>Flask : instrument_app()
OTel->>Celery : instrument()
OTel->>DB : instrument()
OTel->>Cache : instrument()
OTel->>HTTP : instrument()
OTel->>App : 注册 shutdown_tracer
App->>OTel : worker_init.connect(init_celery_worker)
Note over OTel,App : OpenTelemetry 初始化完成
```

**Diagram sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

**Section sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

### 资源属性与采样配置
OpenTelemetry 使用 `Resource` 定义服务元数据，并通过 `ParentBasedTraceIdRatio` 实现采样控制。

```mermaid
flowchart TD
Start([应用启动]) --> Setup["setup_context_propagation()"]
Setup --> Resource["创建 Resource"]
Resource --> Attributes["设置资源属性"]
Attributes --> ServiceName["service.name: dify"]
Attributes --> ServiceVersion["service.version: 版本信息"]
Attributes --> Environment["deployment.environment: 环境"]
Attributes --> Host["host.name: 主机名"]
Attributes --> OS["os.type: 操作系统"]
Attributes --> Git["custom.deployment.git_commit: Git 提交"]
Resource --> Sampler["创建 Sampler"]
Sampler --> SamplingRate["采样率: OTEL_SAMPLING_RATE"]
Sampler --> ParentBased["ParentBasedTraceIdRatio"]
ParentBased --> Provider["创建 TracerProvider"]
Provider --> Exporter["配置 Exporter"]
Exporter --> OTLP["OTLP Exporter"]
OTLP --> Protocol["协议: grpc/http"]
OTLP --> Endpoint["端点: OTLP_BASE_ENDPOINT"]
OTLP --> Headers["认证: OTLP_API_KEY"]
Provider --> BatchProcessor["添加 BatchSpanProcessor"]
BatchProcessor --> Queue["队列大小: OTEL_MAX_QUEUE_SIZE"]
BatchProcessor --> BatchSize["批处理大小: OTEL_MAX_EXPORT_BATCH_SIZE"]
BatchProcessor --> Schedule["调度延迟: OTEL_BATCH_EXPORT_SCHEDULE_DELAY"]
BatchProcessor --> Timeout["超时: OTEL_BATCH_EXPORT_TIMEOUT"]
Provider --> MeterProvider["设置 MeterProvider"]
MeterProvider --> MetricReader["PeriodicExportingMetricReader"]
MetricReader --> MetricInterval["导出间隔: OTEL_METRIC_EXPORT_INTERVAL"]
MetricReader --> MetricTimeout["导出超时: OTEL_METRIC_EXPORT_TIMEOUT"]
Provider --> Instrumentors["初始化 Instrumentors"]
Instrumentors --> Flask["FlaskInstrumentor"]
Instrumentors --> Celery["CeleryInstrumentor"]
Instrumentors --> SQLAlchemy["SQLAlchemyInstrumentor"]
Instrumentors --> Redis["RedisInstrumentor"]
Instrumentors --> Requests["RequestsInstrumentor"]
Instrumentors --> Exception["ExceptionLoggingHandler"]
End([初始化完成])
```

**Diagram sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

**Section sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

## Sentry 错误监控系统设置

### Sentry 配置参数
Sentry 的配置通过 `SentryConfig` 类进行管理，支持 DSN、采样率等关键参数设置。

```mermaid
classDiagram
class SentryConfig {
+Optional[str] SENTRY_DSN
+NonNegativeFloat SENTRY_TRACES_SAMPLE_RATE
+NonNegativeFloat SENTRY_PROFILES_SAMPLE_RATE
}
SentryConfig --> BaseSettings : "继承"
```

**Diagram sources**
- [sentry_config.py](file://api/configs/extra/sentry_config.py#L1-L28)

**Section sources**
- [sentry_config.py](file://api/configs/extra/sentry_config.py#L1-L28)

### Sentry 初始化流程
Sentry 在应用启动时通过 `ext_sentry.py` 进行初始化，集成 Flask 和 Celery 的错误监控。

```mermaid
sequenceDiagram
participant App as DifyApp
participant Sentry as Sentry SDK
participant Flask as FlaskIntegration
participant Celery as CeleryIntegration
App->>Sentry : init_app()
Sentry->>Sentry : sentry_sdk.init()
Sentry->>Sentry : 设置 DSN
Sentry->>Sentry : 添加 FlaskIntegration
Sentry->>Sentry : 添加 CeleryIntegration
Sentry->>Sentry : 设置 ignore_errors
Sentry->>Sentry : 设置 traces_sample_rate
Sentry->>Sentry : 设置 profiles_sample_rate
Sentry->>Sentry : 设置 environment
Sentry->>Sentry : 设置 release
Sentry->>Sentry : 设置 before_send 钩子
Sentry-->>App : 初始化完成
Note over Sentry,App : Sentry 错误监控已启用
```

**Diagram sources**
- [ext_sentry.py](file://api/extensions/ext_sentry.py#L0-L40)

**Section sources**
- [ext_sentry.py](file://api/extensions/ext_sentry.py#L0-L40)

### 错误过滤与处理
Sentry 通过 `before_send` 钩子函数过滤特定错误，避免不必要的错误上报。

```mermaid
flowchart TD
Start([错误发生]) --> BeforeSend["before_send(event, hint)"]
BeforeSend --> HasExcInfo{"hint 中有 exc_info?"}
HasExcInfo --> |是| GetExcValue["获取 exc_value"]
GetExcValue --> ParseError{"parse_error.defaultErrorResponse 在 exc_value 中?"}
ParseError --> |是| DropEvent["丢弃事件"]
ParseError --> |否| ReturnEvent["返回事件"]
HasExcInfo --> |否| ReturnEvent
ReturnEvent --> SendToSentry["发送到 Sentry"]
DropEvent --> Discard["丢弃"]
style DropEvent fill:#f9f,stroke:#333
style SendToSentry fill:#bbf,stroke:#333
```

**Diagram sources**
- [ext_sentry.py](file://api/extensions/ext_sentry.py#L0-L40)

**Section sources**
- [ext_sentry.py](file://api/extensions/ext_sentry.py#L0-L40)

## Prometheus 与 Grafana 集成

### 指标导出配置
OpenTelemetry 通过 `PeriodicExportingMetricReader` 将指标导出到 Prometheus 兼容的端点。

```mermaid
classDiagram
class MeterProvider {
+list[metric_readers]
}
class PeriodicExportingMetricReader {
+int export_interval_millis
+int export_timeout_millis
}
class HTTPMetricExporter {
+str endpoint
+dict headers
}
MeterProvider --> PeriodicExportingMetricReader : "包含"
PeriodicExportingMetricReader --> HTTPMetricExporter : "使用"
HTTPMetricExporter --> OTLP : "导出到 OTLP"
OTLP --> Prometheus : "通过 Prometheus 接收器"
Prometheus --> Grafana : "提供数据源"
```

**Diagram sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

**Section sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

### Grafana 仪表板集成
系统通过 OpenSearch Dashboards 提供可视化界面，与 Grafana 类似，支持指标展示。

```mermaid
graph TB
subgraph "数据源"
OTel[OpenTelemetry]
Prometheus[(Prometheus)]
OpenSearch[(OpenSearch)]
end
subgraph "可视化"
Grafana[Grafana]
OpenSearchDashboards[OpenSearch Dashboards]
end
OTel --> |OTLP| OpenSearch
Prometheus --> |远程写入| OpenSearch
OpenSearch --> OpenSearchDashboards
OpenSearch --> Grafana
Grafana --> Dashboard1["API 响应时间仪表板"]
Grafana --> Dashboard2["错误率仪表板"]
Grafana --> Dashboard3["系统资源仪表板"]
OpenSearchDashboards --> Dashboard4["工作流日志仪表板"]
style Grafana fill:#f96,stroke:#333
style OpenSearchDashboards fill:#04f,stroke:#333
```

**Diagram sources**
- [docker/volumes/opensearch/opensearch_dashboards.yml](file://docker/volumes/opensearch/opensearch_dashboards.yml#L0-L30)

**Section sources**
- [docker/volumes/opensearch/opensearch_dashboards.yml](file://docker/volumes/opensearch/opensearch_dashboards.yml#L0-L30)

## 日志收集与分析最佳实践

### 日志数据模型
系统定义了 `workflow_app_logs` 表用于存储工作流应用日志，支持多租户隔离。

```mermaid
erDiagram
WORKFLOW_APP_LOGS {
uuid id PK
uuid tenant_id FK
uuid app_id FK
uuid workflow_id FK
uuid workflow_run_id FK
string created_from
string created_by_role
uuid created_by FK
timestamp created_at
}
TENANTS {
uuid id PK
string name
}
APPS {
uuid id PK
string name
}
WORKFLOWS {
uuid id PK
string name
}
USERS {
uuid id PK
string email
}
WORKFLOW_APP_LOGS ||--o{ TENANTS : "属于"
WORKFLOW_APP_LOGS ||--o{ APPS : "属于"
WORKFLOW_APP_LOGS ||--o{ WORKFLOWS : "属于"
WORKFLOW_APP_LOGS ||--o{ USERS : "由...创建"
```

**Diagram sources**
- [workflow.py](file://api/models/workflow.py#L816-L849)

**Section sources**
- [workflow.py](file://api/models/workflow.py#L816-L849)

### ELK/EFK 栈集成
系统通过 OpenSearch（Elasticsearch 分支）实现日志存储与分析，与 Fluentd/Kibana 架构类似。

```mermaid
flowchart LR
subgraph "数据采集"
App[Dify 应用]
OTel[OpenTelemetry Collector]
end
subgraph "数据处理"
Fluentd[Fluentd/Fluent Bit]
Pipeline["处理管道"]
end
subgraph "数据存储"
OpenSearch[OpenSearch 集群]
Index["索引: workflow-logs-*"]
end
subgraph "数据分析"
OpenSearchDashboards[OpenSearch Dashboards]
Search["全文搜索"]
Aggregation["聚合分析"]
Visualization["可视化"]
end
App --> |OTLP| OTel
OTel --> |gRPC/HTTP| Fluentd
Fluentd --> |批量写入| Pipeline
Pipeline --> |索引| Index
Index --> OpenSearch
OpenSearch --> OpenSearchDashboards
OpenSearchDashboards --> Search
OpenSearchDashboards --> Aggregation
OpenSearchDashboards --> Visualization
style OpenSearch fill:#04f,stroke:#333
style OpenSearchDashboards fill:#04f,stroke:#333
```

**Diagram sources**
- [docker/volumes/opensearch/opensearch_dashboards.yml](file://docker/volumes/opensearch/opensearch_dashboards.yml#L0-L30)
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

**Section sources**
- [docker/volumes/opensearch/opensearch_dashboards.yml](file://docker/volumes/opensearch/opensearch_dashboards.yml#L0-L30)
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

## 关键监控指标

### API 性能指标
系统监控关键 API 的响应时间和错误率。

```mermaid
table
| 指标名称 | 类型 | 描述 | 采集方式 |
|--------|-----|------|--------|
| http.server.response.count | Counter | HTTP 响应计数 | OpenTelemetry Flask Instrumentor |
| http.server.duration | Histogram | HTTP 请求持续时间 | OpenTelemetry |
| http.server.error.count | Counter | HTTP 错误计数 | OpenTelemetry |
| api.response.time.p95 | Gauge | API 响应时间 95 分位 | Prometheus |
| api.error.rate | Gauge | API 错误率 | Prometheus |
```

**Section sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

### 系统资源指标
监控系统级别的资源使用情况。

```mermaid
table
| 指标名称 | 类型 | 描述 | 采集方式 |
|--------|-----|------|--------|
| process.cpu.usage | Gauge | CPU 使用率 | OpenTelemetry |
| process.memory.usage | Gauge | 内存使用量 | OpenTelemetry |
| system.disk.usage | Gauge | 磁盘使用率 | Prometheus Node Exporter |
| system.network.io | Gauge | 网络 I/O | Prometheus Node Exporter |
| celery.queue.length | Gauge | Celery 队列长度 | Prometheus |
```

**Section sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

### 应用业务指标
监控核心业务功能的性能。

```mermaid
table
| 指标名称 | 类型 | 描述 | 采集方式 |
|--------|-----|------|--------|
| app.workflow.run.duration | Histogram | 工作流执行时长 | OpenTelemetry |
| app.workflow.run.success | Counter | 工作流成功次数 | OpenTelemetry |
| app.workflow.run.failure | Counter | 工作流失败次数 | OpenTelemetry |
| app.llm.token.usage | Counter | LLM Token 使用量 | OpenTelemetry |
| app.embedding.duration | Histogram | 嵌入生成时长 | OpenTelemetry |
```

**Section sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

## 告警规则配置

### 告警规则定义
基于 Prometheus 的告警规则配置。

```mermaid
table
| 告警名称 | 条件 | 持续时间 | 严重程度 | 通知方式 |
|--------|------|--------|--------|--------|
| HighAPIErrorRate | api.error.rate > 0.1 | 5m | critical | 邮件、Webhook |
| HighResponseTime | api.response.time.p95 > 5s | 10m | warning | 邮件 |
| HighCPUUsage | process.cpu.usage > 0.8 | 15m | warning | 邮件 |
| HighMemoryUsage | process.memory.usage > 80% | 15m | warning | 邮件 |
| WorkflowFailureRate | app.workflow.run.failure / app.workflow.run.total > 0.2 | 30m | critical | 邮件、Webhook |
| CeleryQueueBacklog | celery.queue.length > 100 | 5m | warning | 邮件 |
```

**Section sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)

## 故障排查流程

### 故障排查流程图
标准化的故障排查流程。

```mermaid
flowchart TD
Start([系统告警]) --> CheckAlert["检查告警详情"]
CheckAlert --> IdentifyService["识别受影响服务"]
IdentifyService --> CheckLogs["检查相关日志"]
CheckLogs --> OpenSearch["查询 OpenSearch"]
OpenSearch --> FilterBy["按服务/时间/错误码过滤"]
FilterBy --> AnalyzeLogs["分析日志模式"]
AnalyzeLogs --> CheckMetrics["检查监控指标"]
CheckMetrics --> Prometheus["查询 Prometheus"]
Prometheus --> CheckTrend["检查指标趋势"]
CheckTrend --> Correlate["关联日志与指标"]
Correlate --> IdentifyRootCause["识别根本原因"]
IdentifyRootCause --> ApplyFix["应用修复措施"]
ApplyFix --> VerifyFix["验证修复效果"]
VerifyFix --> Monitor["持续监控"]
Monitor --> Resolved{问题解决?}
Resolved --> |是| End([告警恢复])
Resolved --> |否| Escalate["升级处理"]
Escalate --> Team["通知相关团队"]
Team --> DeepAnalysis["深入分析"]
DeepAnalysis --> ApplyFix
```

**Section sources**
- [ext_otel.py](file://api/extensions/ext_otel.py#L0-L259)
- [ext_sentry.py](file://api/extensions/ext_sentry.py#L0-L40)