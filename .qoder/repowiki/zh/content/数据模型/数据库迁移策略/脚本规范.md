# 脚本规范

<cite>
**本文档中引用的文件**  
- [env.py](file://api/migrations/env.py)
- [alembic.ini](file://api/migrations/alembic.ini)
- [data_migration.py](file://api/services/plugin/data_migration.py)
- [commands.py](file://api/commands.py)
</cite>

## 目录
1. [引言](#引言)
2. [迁移脚本命名约定与版本号生成规则](#迁移脚本命名约定与版本号生成规则)
3. [upgrade() 和 downgrade() 函数的标准结构](#upgrade-和-downgrade-函数的标准结构)
4. [使用 Alembic op 类方法进行表结构变更](#使用-alembic-op-类方法进行表结构变更)
5. [不同类型变更的标准代码模板](#不同类型变更的标准代码模板)
6. [数据迁移与数据转换处理](#数据迁移与数据转换处理)
7. [迁移脚本中的注释规范与文档要求](#迁移脚本中的注释规范与文档要求)

## 引言
Dify 平台使用 Alembic 作为数据库迁移工具，确保数据库模式变更的安全性和可追溯性。本规范详细说明了编写数据库迁移脚本的最佳实践，涵盖命名约定、函数结构、操作方法、数据迁移策略以及文档要求，旨在提升团队协作效率和代码质量。

**Section sources**
- [env.py](file://api/migrations/env.py#L1-L111)

## 迁移脚本命名约定与版本号生成规则
Dify 的数据库迁移脚本位于 `api/migrations/versions/` 目录下，采用时间戳加描述性后缀的方式命名，格式为 `YYYYMMDDHHMMSS_description.py`。例如：`20240118102154_add_dataset_and_document.py`。

时间戳部分精确到秒，确保迁移脚本的执行顺序严格按时间先后排列。描述性后缀应简洁明了地概括本次迁移的主要目的，使用小写字母和下划线连接，避免空格和特殊字符。

该命名机制由 Alembic 自动生成，通过 `alembic revision --autogenerate -m "description"` 命令创建新脚本时，Alembic 会自动插入当前时间戳。

**Section sources**
- [env.py](file://api/migrations/env.py#L1-L111)

## upgrade() 和 downgrade() 函数的标准结构
每个迁移脚本必须定义 `upgrade()` 和 `downgrade()` 两个函数。`upgrade()` 函数用于应用变更，`downgrade()` 函数用于撤销变更，保证数据库状态可回滚。

函数内部应遵循以下结构：
1. **操作顺序**：按依赖关系顺序执行操作，如先创建表再添加外键。
2. **错误处理**：利用 Alembic 的内置事务管理，所有操作在事务中执行，一旦失败自动回滚。
3. **事务管理**：Alembic 默认在 `context.begin_transaction()` 中运行迁移，无需手动管理事务。

```python
def upgrade():
    # 执行升级操作
    pass

def downgrade():
    # 执行降级操作
    pass
```

**Section sources**
- [env.py](file://api/migrations/env.py#L85-L109)

## 使用 Alembic op 类方法进行表结构变更
Alembic 提供了 `op` 模块来执行各种数据库操作。常用方法包括：
- `op.create_table()`：创建新表
- `op.drop_table()`：删除表
- `op.add_column()`：添加字段
- `op.drop_column()`：删除字段
- `op.alter_column()`：修改字段属性
- `op.create_index()`：创建索引
- `op.drop_index()`：删除索引

这些方法封装了跨数据库的 SQL 差异，确保迁移脚本在不同数据库后端（如 PostgreSQL、MySQL）上的一致性。

**Section sources**
- [env.py](file://api/migrations/env.py#L45-L87)

## 不同类型变更的标准代码模板
### 添加字段
```python
op.add_column('table_name', sa.Column('new_column', sa.String(), nullable=True))
```

### 修改字段
```python
op.alter_column('table_name', 'column_name', 
                existing_type=sa.String(),
                type_=sa.Text(),
                nullable=True)
```

### 重命名字段
```python
op.alter_column('table_name', 'old_name', new_column_name='new_name')
```

### 删除字段
```python
op.drop_column('table_name', 'column_name')
```

### 创建表
```python
op.create_table(
    'new_table',
    sa.Column('id', sa.String(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.PrimaryKeyConstraint('id')
)
```

**Section sources**
- [env.py](file://api/migrations/env.py#L45-L87)

## 数据迁移与数据转换处理
对于涉及数据变更的迁移（如字段重命名、类型转换），应在 `upgrade()` 函数中实现数据迁移逻辑。建议采用分批处理方式，避免长时间锁定表。

性能优化措施包括：
- 使用 `LIMIT` 和 `OFFSET` 分页处理大数据集
- 在事务外执行查询，在事务内执行更新
- 批量提交更新以减少事务开销

示例代码结构：
```python
# 查询旧数据
result = op.get_bind().execute("SELECT id, old_field FROM table")
for row in result:
    # 转换并更新
    new_value = transform(row.old_field)
    op.execute(f"UPDATE table SET new_field = '{new_value}' WHERE id = '{row.id}'")
```

实际项目中，类似的数据迁移逻辑可在 `data_migration.py` 中找到，采用分页和批量更新策略处理插件元数据迁移。

**Section sources**
- [data_migration.py](file://api/services/plugin/data_migration.py#L58-L196)
- [commands.py](file://api/commands.py#L554-L586)

## 迁移脚本中的注释规范与文档要求
每个迁移脚本应包含清晰的注释，说明变更的目的、影响范围和潜在风险。注释应使用英文编写，遵循 Python PEP 8 规范。

推荐结构：
```python
"""Migration description.

This migration adds a new column to support feature X.
It affects the following tables: table_a, table_b.
No data migration is required.
"""
```

此外，重大变更应在项目文档中记录，并通知相关团队成员，确保迁移过程透明可控。

**Section sources**
- [env.py](file://api/migrations/env.py#L0-L50)